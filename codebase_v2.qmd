---
title: "Appendix (Final Project) - MATH 5027"
author: "Matthew Joel"
format:
  html:
    self-contained: true
execute:
  warning: false
  message: false
---

## Libraries

```{r}
library(tidyverse)
library(tidyquant)
library(quantmod)
library(zoo)
library(xts)
library(lubridate)
library(ggplot2)
library(forecast)
library(tseries)
library(lmtest)
library(prophet)
library(lightgbm)

has_seastests <- require(seastests, quietly = TRUE)

```



## Data Creation and Covariates

```{r}

start_date <- as.Date("2010-01-01")
end_date   <- Sys.Date()

# Market data: SPY daily prices (OHLCV)
spy <- tq_get("SPY", from = start_date, to = end_date) %>%
  select(date, open, high, low, close, volume, adjusted) %>%
  arrange(date) %>%
  mutate(
    ret_simple = adjusted / lag(adjusted) - 1,
    ret_log    = log(adjusted) - log(lag(adjusted))
  )

# Macro series from FRED
symbols <- c("DFF", "DGS10", "DGS2", "T10YIE", "VIXCLS")
getSymbols(symbols, src = "FRED", from = start_date, to = end_date)

fred_xts <- do.call(merge, c(mget(symbols), list(all = TRUE)))
colnames(fred_xts) <- symbols

fred <- tibble(
  date   = as.Date(index(fred_xts)),
  DFF    = as.numeric(fred_xts$DFF),
  DGS10  = as.numeric(fred_xts$DGS10),
  DGS2   = as.numeric(fred_xts$DGS2),
  T10YIE = as.numeric(fred_xts$T10YIE),
  VIXCLS = as.numeric(fred_xts$VIXCLS)
) %>%
  arrange(date)

# Join to SPY trading days, fill macros, then engineer features
df <- spy %>%
  left_join(fred, by = "date") %>%
  arrange(date) %>%
  tidyr::fill(DFF, DGS10, DGS2, T10YIE, VIXCLS, .direction = "down") %>%
  mutate(
    curve_10y_2y = DGS10 - DGS2,
    d_DFF   = DFF - lag(DFF),
    d_DGS10 = DGS10 - lag(DGS10),
    d_VIX   = VIXCLS - lag(VIXCLS),
    rv_20   = zoo::rollapply(ret_log, width = 20, FUN = sd, fill = NA, align = "right")
  )

write_csv(df, "spy_fred_dataset.csv")


```

```{r}
set.seed(5027)

df <- read.csv("spy_fred_dataset.csv")

df$date <- as.Date(df$date)
df <- df[order(df$date), ]

# Quick checks
dim(df)
head(df)
tail(df)
str(df)

# Missingness check (expected early NAs from returns, deltas, rv_20)
colSums(is.na(df))

#########################################
###   Choose target + train/test split  ###
#########################################

# Target for all models (keeps comparisons clean)
# Option A: adjusted price level
y_var <- "adjusted"

# Option B: log returns
# y_var <- "ret_log"

y_all <- df[[y_var]]
date_all <- df$date

# Hold out last ~1 year of trading days for testing
test_n <- 252

n <- length(y_all)
train_idx <- 1:(n - test_n)
test_idx  <- (n - test_n + 1):n

y_train <- y_all[train_idx]
y_test  <- y_all[test_idx]

date_train <- date_all[train_idx]
date_test  <- date_all[test_idx]

# For forecast package functions
y_train_ts <- ts(y_train, frequency = 1)
y_all_ts   <- ts(y_all, frequency = 1)

# Helper metrics (keeps model comparison consistent)
calc_metrics <- function(actual, pred){
  data.frame(
    RMSE = sqrt(mean((actual - pred)^2, na.rm = TRUE)),
    MAE  = mean(abs(actual - pred), na.rm = TRUE),
    MAPE = mean(abs((actual - pred) / actual), na.rm = TRUE) * 100
  )
}

```


## Exploratory Data Analysis

```{r}
# Basic time series plot
p1 <- ggplot(df, aes(x = date, y = .data[[y_var]])) +
  geom_line() +
  xlab("") +
  ylab(y_var) +
  ggtitle(paste("Time Series:", y_var))
print(p1)

# also look at returns for volatility context
p2 <- ggplot(df, aes(x = date, y = ret_log)) +
  geom_line() +
  xlab("") +
  ylab("ret_log") +
  ggtitle("SPY Log Returns (context for volatility)")
print(p2)

# Summary stats for target
summary(y_train)
quantile(y_train, probs = c(0.01, 0.05, 0.5, 0.95, 0.99), na.rm = TRUE)

```

## MODEL 1 (Midterm non-ARIMA): Holt


```{r}
# Two Holt versions (like our class notes): linear trend and damped trend
holt_lin <- holt(y_train_ts, h = test_n)
holt_damped <- holt(y_train_ts, damped = TRUE, phi = 0.8, h = test_n)

# Model summaries
summary(holt_lin)
summary(holt_damped)

# Plots
autoplot(holt_lin) + ggtitle("Holt - Linear Trend Forecast")
autoplot(holt_damped) + ggtitle("Holt - Damped Trend Forecast")

# Test set predictions + metrics
holt_lin_pred <- as.numeric(holt_lin$mean)
holt_damped_pred <- as.numeric(holt_damped$mean)

holt_lin_metrics <- calc_metrics(y_test, holt_lin_pred)
holt_damped_metrics <- calc_metrics(y_test, holt_damped_pred)

holt_lin_metrics
holt_damped_metrics

# Forecast table (test period)
holt_lin_test_tbl <- data.frame(
  date = date_test,
  actual = y_test,
  pred = holt_lin_pred,
  lo80 = as.numeric(holt_lin$lower[, "80%"]),
  hi80 = as.numeric(holt_lin$upper[, "80%"]),
  lo95 = as.numeric(holt_lin$lower[, "95%"]),
  hi95 = as.numeric(holt_lin$upper[, "95%"])
)
head(holt_lin_test_tbl)
tail(holt_lin_test_tbl)
```


## MODEL 2 (Midterm): ARIMA / SARIMA + diagnostics

```{r}
#############################
### Stationarity checks     ###
#############################

# ADF/KPSS on the training series (these outputs support ARIMA assumptions)
k_adf <- trunc((length(y_train_ts) - 1)^(1/3))
adf.test(y_train_ts, k = k_adf)
kpss.test(y_train_ts, null = "Trend")

# First difference checks
y_train_diff1 <- diff(y_train_ts, differences = 1)

par(mfrow = c(1,2))
plot(y_train_ts, main = paste(y_var, "- training"))
plot(y_train_diff1, main = paste(y_var, "- 1st difference"))
par(mfrow = c(1,1))

adf.test(y_train_diff1, k = trunc((length(y_train_diff1) - 1)^(1/3)))
kpss.test(y_train_diff1, null = "Trend")

# ACF/PACF
par(mfrow = c(1,2))
acf(y_train_diff1, main = "ACF (1st diff)")
pacf(y_train_diff1, main = "PACF (1st diff)")
par(mfrow = c(1,1))

#############################
### Seasonality checks      ###
#############################

# For trading-day data, weekly “seasonality” is at most mild.
y_train_week_ts <- ts(y_train, frequency = 5)

try(print(nsdiffs(y_train_week_ts, test = "ch")), silent = TRUE)
try(print(nsdiffs(y_train_week_ts, test = "ocsb")), silent = TRUE)

if(has_seastests){
  try(print(seastests::ch.test(y_train_week_ts, type = "dummy")), silent = TRUE)
}

#############################
### Fit ARIMA (nonseasonal) ###
#############################

# auto.arima for baseline ARIMA selection
arima_mod <- auto.arima(y_train_ts, seasonal = FALSE, trace = FALSE)

summary(arima_mod)
arimaorder(arima_mod)

# Coefficient significance
coeftest(arima_mod)

# Residual diagnostics
checkresiduals(arima_mod)
qqnorm(resid(arima_mod)); qqline(resid(arima_mod))

# Ljung-Box (showing residual autocorrelation check)
Box.test(resid(arima_mod), type = "Ljung-Box", lag = 20)
Box.test(resid(arima_mod), type = "Ljung-Box", lag = 20, fitdf = length(arima_mod$coef))

# Forecast into test window
arima_fc <- forecast(arima_mod, h = test_n, level = c(80, 95))
autoplot(arima_fc) + ggtitle("ARIMA Forecast (Test Window)")

arima_pred <- as.numeric(arima_fc$mean)
arima_metrics <- calc_metrics(y_test, arima_pred)
arima_metrics

arima_test_tbl <- data.frame(
  date = date_test,
  actual = y_test,
  pred = arima_pred,
  lo80 = as.numeric(arima_fc$lower[, "80%"]),
  hi80 = as.numeric(arima_fc$upper[, "80%"]),
  lo95 = as.numeric(arima_fc$lower[, "95%"]),
  hi95 = as.numeric(arima_fc$upper[, "95%"])
)
head(arima_test_tbl)
tail(arima_test_tbl)

#########################################
### Fit SARIMA (weekly m=5)   ###
#########################################

sarima_week_mod <- auto.arima(y_train_week_ts, seasonal = TRUE, trace = FALSE)

summary(sarima_week_mod)
arimaorder(sarima_week_mod)
coeftest(sarima_week_mod)
checkresiduals(sarima_week_mod)

sarima_week_fc <- forecast(sarima_week_mod, h = test_n, level = c(80, 95))
sarima_week_pred <- as.numeric(sarima_week_fc$mean)
sarima_week_metrics <- calc_metrics(y_test, sarima_week_pred)
sarima_week_metrics

```


## MODEL 3 (Final): Prophet (with CV)

```{r}
# Prophet needs ds (date) and y
prophet_train <- data.frame(
  ds = date_train,
  y  = y_train
)

# Baseline Prophet model
prophet_mod <- prophet(
  prophet_train,
  growth = "linear",
  yearly.seasonality = TRUE,
  weekly.seasonality = TRUE,
  daily.seasonality = FALSE,
  interval.width = 0.95
)

# Predict over train + test dates exactly (no weekend mismatch)
future_train_test <- data.frame(ds = c(date_train, date_test))
prophet_fc <- predict(prophet_mod, future_train_test)

# Pull test predictions
train_n <- length(date_train)
prophet_pred <- prophet_fc$yhat[(train_n + 1):(train_n + test_n)]

# Accuracy on test set
prophet_metrics <- calc_metrics(y_test, prophet_pred)
prophet_metrics

# Prophet plots
plot(prophet_mod, prophet_fc)
prophet_plot_components(prophet_mod, prophet_fc)

# Table for test period
prophet_test_tbl <- data.frame(
  date = date_test,
  actual = y_test,
  pred = prophet_pred,
  lo95 = prophet_fc$yhat_lower[(train_n + 1):(train_n + test_n)],
  hi95 = prophet_fc$yhat_upper[(train_n + 1):(train_n + test_n)]
)
head(prophet_test_tbl)
tail(prophet_test_tbl)


##############################
### Prophet cross-validation ###
##############################

# CV settings (integers) and units
initial_days <- 2000
period_days  <- 365
horizon_days <- 90

prophet_cv <- prophet::cross_validation(
  model   = prophet_mod,
  horizon = horizon_days,
  units   = "days",
  period  = period_days,
  initial = initial_days
)

head(prophet_cv)
tail(prophet_cv)

prophet_cv_perf <- prophet::performance_metrics(prophet_cv)
prophet_cv_perf

prophet::plot_cross_validation_metric(prophet_cv, metric = "rmse")


```


## MODEL 4 (Final): LightGBM (with time series CV)

```{r}
############################################
### Build supervised ML data (next-day y) ###
############################################

# Predict next trading day value using features known today
df_ml <- df %>%
  arrange(date) %>%
  mutate(
    y_next      = lead(.data[[y_var]], 1),
    y_next_date = lead(date, 1)
  )

# Add lagged features
# Keep lags modest so code runs fast
max_lag <- 10

for(i in 1:max_lag){
  df_ml <- df_ml %>%
    mutate(tmp = dplyr::lag(.data[[y_var]], n = i))
  names(df_ml)[ncol(df_ml)] <- paste0(y_var, "_lag", i)
}

for(i in 1:max_lag){
  df_ml <- df_ml %>%
    mutate(tmp2 = dplyr::lag(ret_log, n = i))
  names(df_ml)[ncol(df_ml)] <- paste0("ret_log_lag", i)
}

# Keep a future-row (last known date) for a 1-step-ahead “real” forecast later
df_ml_future_row <- df_ml %>% tail(1)

# Select feature columns
feature_cols <- c(
  # current day info (known at time t)
  y_var, "volume", "ret_log", "rv_20",
  "VIXCLS", "curve_10y_2y", "d_DFF", "d_DGS10", "d_VIX",
  paste0(y_var, "_lag", 1:max_lag),
  paste0("ret_log_lag", 1:max_lag)
)

# Remove rows with NA in features or target
df_ml_clean <- df_ml %>%
  select(date, y_next_date, y_next, all_of(feature_cols)) %>%
  drop_na()

# Split ML train/test by TARGET DATE (y_next_date) so it matches date_test
test_start_date <- min(date_test)

train_ml <- df_ml_clean %>% filter(y_next_date < test_start_date)
test_ml  <- df_ml_clean %>% filter(y_next_date >= test_start_date)

# Matrices for LightGBM
X_train_ml <- as.matrix(train_ml[, feature_cols])
y_train_ml <- train_ml$y_next

X_test_ml <- as.matrix(test_ml[, feature_cols])
y_test_ml <- test_ml$y_next

# Confirm test dates align
range(test_ml$y_next_date)
range(date_test)
nrow(test_ml)

##############################
### Time series CV function ###
##############################

lgb_ts_cv <- function(X, y, cutoffs, horizon, params, nrounds = 200){
  out <- data.frame(cutoff = cutoffs, rmse = NA_real_)
  for(i in 1:length(cutoffs)){
    c0 <- cutoffs[i]
    train_idx <- 1:c0
    val_idx <- (c0 + 1):(c0 + horizon)

    dtrain <- lgb.Dataset(data = X[train_idx, ], label = y[train_idx])
    dval   <- lgb.Dataset(data = X[val_idx, ], label = y[val_idx])

    mod <- lgb.train(
      params = params,
      data = dtrain,
      nrounds = nrounds,
      valids = list(valid = dval),
      verbose = -1
    )

    preds <- predict(mod, X[val_idx, ])
    out$rmse[i] <- sqrt(mean((preds - y[val_idx])^2))
  }
  out
}

############################################
### LightGBM hyperparameter "mini-grid"   ###
############################################

# Cutoffs for expanding-window CV inside training set
horizon <- 60
initial <- 2000
n_train_ml <- nrow(train_ml)

max_cutoff <- n_train_ml - horizon
cutoffs <- floor(seq(from = initial, to = max_cutoff, length.out = 5))
cutoffs <- unique(cutoffs)

cutoffs

grid <- expand.grid(
  num_leaves = c(31, 63),
  learning_rate = c(0.05, 0.1),
  min_data_in_leaf = c(20, 50),
  feature_fraction = c(0.8),
  bagging_fraction = c(0.8)
)

grid$rmse_cv <- NA_real_

for(g in 1:nrow(grid)){
  params_g <- list(
    objective = "regression",
    metric = "l2",
    num_leaves = grid$num_leaves[g],
    learning_rate = grid$learning_rate[g],
    min_data_in_leaf = grid$min_data_in_leaf[g],
    feature_fraction = grid$feature_fraction[g],
    bagging_fraction = grid$bagging_fraction[g],
    bagging_freq = 1L
  )

  cv_out <- lgb_ts_cv(
    X = X_train_ml,
    y = y_train_ml,
    cutoffs = cutoffs,
    horizon = horizon,
    params = params_g,
    nrounds = 200
  )

  grid$rmse_cv[g] <- mean(cv_out$rmse)
  print(cbind(grid[g, ], mean_rmse = grid$rmse_cv[g]))
}

grid <- grid[order(grid$rmse_cv), ]
grid

best_params_row <- grid[1, ]
best_params_row

best_params <- list(
  objective = "regression",
  metric = "l2",
  num_leaves = best_params_row$num_leaves,
  learning_rate = best_params_row$learning_rate,
  min_data_in_leaf = best_params_row$min_data_in_leaf,
  feature_fraction = best_params_row$feature_fraction,
  bagging_fraction = best_params_row$bagging_fraction,
  bagging_freq = 1L
)

############################################
### Train final LightGBM + test evaluation ###
############################################

dtrain_full <- lgb.Dataset(data = X_train_ml, label = y_train_ml)

lgb_mod <- lgb.train(
  params = best_params,
  data = dtrain_full,
  nrounds = 300,
  verbose = -1
)

# Fast predict config (we used in class)
lgb.configure_fast_predict(lgb_mod)

lgb_pred <- predict(lgb_mod, X_test_ml)

# Metrics (on the same test period)
lgb_metrics <- calc_metrics(y_test_ml, lgb_pred)
lgb_metrics

# Put predictions in a table with target dates
lgb_test_tbl <- data.frame(
  date = test_ml$y_next_date,
  actual = y_test_ml,
  pred = lgb_pred
)
head(lgb_test_tbl)
tail(lgb_test_tbl)

# Feature importance
imp <- lgb.importance(lgb_mod)
head(imp, 20)
lgb.plot.importance(imp, top_n = 20)

############################################
### One-step-ahead forecast beyond dataset ###
############################################

# Predict the next day after last observed date (1-step ahead)
# Uses the last row's features (macros assumed known "today")
df_future_feat <- df_ml_future_row %>%
  select(all_of(feature_cols))

X_future <- as.matrix(df_future_feat)
lgb_next_pred <- predict(lgb_mod, X_future)
lgb_next_pred

```

## Model Comparison and Future Forecasting

```{r}

#######################################################
###   Compare all 4 models on the SAME test period     ###
#######################################################

# Align LightGBM test predictions to date_test via merge
# (Date alignment matters because ML uses y_next_date)
compare_df <- data.frame(
  date = date_test,
  actual = y_test,
  holt = holt_lin_pred,
  arima = arima_pred,
  prophet = prophet_pred
) %>%
  left_join(lgb_test_tbl %>% select(date, lgbm = pred), by = "date")

head(compare_df)
tail(compare_df)

# Metrics table (test set)
metrics_tbl <- bind_rows(
  Holt = calc_metrics(compare_df$actual, compare_df$holt),
  ARIMA = calc_metrics(compare_df$actual, compare_df$arima),
  Prophet = calc_metrics(compare_df$actual, compare_df$prophet),
  LightGBM = calc_metrics(compare_df$actual, compare_df$lgbm),
  .id = "Model"
)

metrics_tbl

# Plot all test predictions vs actual
plot_long <- compare_df %>%
  pivot_longer(cols = c("actual","holt","arima","prophet","lgbm"),
               names_to = "series",
               values_to = "value")

ggplot(plot_long, aes(x = date, y = value, color = series)) +
  geom_line() +
  xlab("") +
  ylab(y_var) +
  ggtitle("Test Window: Actual vs Model Predictions")

# Save key tables  
write.csv(metrics_tbl, "model_test_metrics.csv", row.names = FALSE)
write.csv(compare_df, "test_predictions_all_models.csv", row.names = FALSE)
write.csv(holt_lin_test_tbl, "holt_test_table.csv", row.names = FALSE)
write.csv(arima_test_tbl, "arima_test_table.csv", row.names = FALSE)
write.csv(prophet_test_tbl, "prophet_test_table.csv", row.names = FALSE)
write.csv(lgb_test_tbl, "lgbm_test_table.csv", row.names = FALSE)

# Forecast into the future (20 steps) 
h_future <- 20

# Holt future forecast (fit on full series)
holt_full <- holt(y_all_ts, h = h_future)
holt_full

# ARIMA future forecast (fit on full series)
arima_full <- auto.arima(y_all_ts, seasonal = FALSE)
arima_full_fc <- forecast(arima_full, h = h_future, level = c(80,95))
arima_full_fc

# Prophet future forecast (includes weekends; filter to weekdays for a trading-day view)
prophet_all <- data.frame(ds = date_all, y = y_all)
prophet_full <- prophet(
  prophet_all,
  yearly.seasonality = TRUE,
  weekly.seasonality = TRUE,
  daily.seasonality = FALSE,
  interval.width = 0.95
)
future_full <- make_future_dataframe(prophet_full, periods = 30, freq = "day")
prophet_full_fc <- predict(prophet_full, future_full)

# Keep next ~20 weekdays
future_only <- prophet_full_fc %>%
  filter(ds > max(date_all)) %>%
  mutate(wday = weekdays(ds)) %>%
  filter(!(wday %in% c("Saturday","Sunday"))) %>%
  slice(1:h_future)

future_only %>% select(ds, yhat, yhat_lower, yhat_upper)

```

